{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eeb4c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\RameshMisale\\Documents\\Profile_data.xlsx\")\n",
    "df1 = df\n",
    "df1['Resubmit'] = pd.to_datetime(df1['Resubmit'])\n",
    "df1['Resubmit'] = df1['Resubmit'].notnull().astype(int)\n",
    "columns_to_fill = ['rcra_non_haz_exempt','halogens_flag','no_reactivity_flag','layered','viscosity','odor_flag','ph_flag',\n",
    "    'flash_point_flag','boiling_point_flag','btu_per_lbs','pumpable_waste_flag','polymerizable_flag','benzene_waste_flag',\n",
    "    'voc_100_ppm','marine_pollutant_flag','origin_code','sds_attached','specific_gravity','benzene_section_flag',\n",
    "    'max_benzene_flag','benzene_water','prohibited_land_disposal','uts_waste','voc_500_ppm','specialpricing_flag',\n",
    "    'intercompany_flag','mgp_flag','pa_waste_catogory','debris','compressed_gas','analytical_ind',\n",
    "    'generatorknowledge_ind','sds_ind','formulary_attached','analytical_attached','sample_provided','mgplock_flag',\n",
    "    'naics_flag','federal_universal_waste','generator_state_universal_waste']\n",
    "df1[columns_to_fill] = df1[columns_to_fill].fillna(0, inplace=False)\n",
    "\n",
    "col = ['water_percentage', 'toc_percentage'] #filling with mean for these 2 columns\n",
    "df1[col] = df1[col].fillna(df1[col].mean(), inplace=False)\n",
    "#df1.isnull().sum()\n",
    "object_columns = df1.select_dtypes(include=['object','datetime64']).columns\n",
    "df_dropped_objects = df1.drop(object_columns, axis=1)\n",
    "# df_dropped_objects.dtypes\n",
    "\n",
    "#It will remove the zero variance features\n",
    "\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(df_dropped_objects)\n",
    "\n",
    "constant_columns = [column for column in df_dropped_objects.columns\n",
    "                    if column not in df_dropped_objects.columns[var_thres.get_support()]]\n",
    "print(f\"Number of constant columns: {len(constant_columns)}\")\n",
    "for feature in constant_columns:\n",
    "    unique_values = df_dropped_objects[feature].unique()\n",
    "    print(f\"Constant column: {feature}\")\n",
    "    print(f\"Unique values: {unique_values}\")\n",
    "    print(\"\\n\")\n",
    "data = df_dropped_objects.drop(constant_columns,axis=1) #dropped the columns here \n",
    "\n",
    "def correlation(dataset,threshold):\n",
    "    col_corr=set()\n",
    "    corr_matrix=dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j]>threshold):\n",
    "                colname=corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "\n",
    "corr_features=correlation(data,0.8)\n",
    "len(set(corr_features))\n",
    "\n",
    "\n",
    "data1=data.drop(corr_features,axis=1) # dropped the correlated features here\n",
    "\n",
    "\n",
    "threshold_percentage = 90 \n",
    "null_percentage = (data1.isnull().sum() / len(data1)) * 100\n",
    "columns_to_drop = null_percentage[null_percentage > threshold_percentage].index\n",
    "data1_dropped = data1.drop(columns=columns_to_drop)\n",
    "#data1_dropped.isnull().sum()\n",
    "\n",
    "data1_dropped = data1_dropped.fillna(0) #filling the null values with 0\n",
    "#data1_dropped.isnull().sum() \n",
    "\n",
    "dff = data1_dropped.drop(columns=['ReturnCount','DaysAssignReadyForGenSign','profile_id','web_profile_number',\n",
    "                                  'DaysSubmitToAssign','DaysAssignReadyForGenSign','DaysReadyForGenSignSentForGenSign',\n",
    "                                  'DaysDocSignReturnedToApproved','container_type_id','DaysInitiatedToSubmitted',\n",
    "'DaysSentForGenSignToDocSignReturned','vendor_id','ContractID','ldr_class_id','CustomerId','CollectionId',\n",
    "'HCSId','Recert','is_template_profile_flag','AssignUser_id','status_code_id','source_code_id','form_code_id',\n",
    "'management_method_code_id','outbound_profile_id','price_type_code_id','parent_profile_id','health_chemical_identity_id',\n",
    "'flammability_chemical_identity_id','reactivity_chemical_identity_id','process_code_id',\n",
    "'SalesrepID','InternalCoordinatorID','MarketDriverID','InsideSalesRepID','requested_process_code_id'],axis=1)\n",
    "dff.shape\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = dff.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(dff.values, i) for i in range(dff.shape[1])]\n",
    "print(vif_data)\n",
    "\n",
    "high_vif_columns = vif_data[vif_data[\"VIF\"] > 5][\"feature\"].tolist()\n",
    "high_vif_columns\n",
    "\n",
    "df_final = dff.drop(columns=high_vif_columns)\n",
    "df_final.shape\n",
    "\n",
    "XX = df_final.drop('Resubmit', axis='columns')\n",
    "yy= df_final['Resubmit']\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX,yy, test_size=0.2,random_state=42,stratify=yy)\n",
    "\n",
    "count_0_class,count_1_class = df_final.Resubmit.value_counts()\n",
    "df_class_0 = df_final[df_final[\"Resubmit\"]==0]\n",
    "df_class_1 = df_final[df_final[\"Resubmit\"]==1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX,yy, test_size=0.2,random_state=15,stratify=yy)\n",
    "\n",
    "df_class_0_under = df_class_0.sample(count_1_class)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1],axis=0)\n",
    "\n",
    "print('Random Under-sampling:')\n",
    "print(df_test_under.Resubmit.value_counts())\n",
    "\n",
    "XX = df_test_under.drop('Resubmit', axis='columns')\n",
    "yy= df_test_under['Resubmit']\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX,yy, test_size=0.2,random_state=42,stratify=yy)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(XX_train, yy_train)\n",
    "y_pred_lr_train = logistic_regression.predict(XX_train)\n",
    "y_pred_lr_test = logistic_regression.predict(XX_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_lr_train = accuracy_score(yy_train, y_pred_lr_train)\n",
    "accuracy_lr_test = accuracy_score(yy_test, y_pred_lr_test)\n",
    "print(f'Logistic Regression Training Accuracy: {accuracy_lr_train}')\n",
    "print(f'Logistic Regression Testing Accuracy: {accuracy_lr_test}')\n",
    "\n",
    "# # classification report\n",
    "# print(classification_report(yy_test, y_pred_lr_test))\n",
    "# print(confusion_matrix(yy_test, y_pred_lr_test))\n",
    "\n",
    "precision_lr_test = precision_score(yy_test, y_pred_lr_test)\n",
    "recall_lr_test = recall_score(yy_test, y_pred_lr_test)\n",
    "f1_lr_test = f1_score(yy_test, y_pred_lr_test)\n",
    "\n",
    "# Display precision, recall, and f1-score\n",
    "print(f'\\nPrecision: {precision_lr_test:.4f}')\n",
    "print(f'Recall: {recall_lr_test:.4f}')\n",
    "print(f'F1-Score: {f1_lr_test:.4f}')\n",
    "\n",
    "\n",
    "# import pickle\n",
    "# file_path = (r'C:\\Users\\RameshMisale\\Downloads\\Harsco_model.pkl')\n",
    "\n",
    "# # Open the file in binary write mode\n",
    "# with open(file_path, 'wb') as file:\n",
    "#     # Use pickle.dump() to serialize and save the data to the file\n",
    "#     pickle.dump(file_path, file)\n",
    "\n",
    "# print(f'Data saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f7b25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(logistic_regression, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "192408c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_case = joblib.load(open(r'C:\\Users\\RameshMisale\\Downloads\\Harsco_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "710242c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\RameshMisale\\\\Downloads\\\\Harsco_model.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming 'model_case' is your trained model\n",
    "# Save the model to a file using joblib\n",
    "joblib.dump(model_case, r'C:\\Users\\RameshMisale\\Downloads\\Harsco_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b201fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('your_file_path.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "176b4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(r'C:\\Users\\RameshMisale\\Downloads\\df_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c3228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
