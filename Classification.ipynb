{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74e1dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3725318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\RameshMisale\\Documents\\Profile_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eebc98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab35852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Resubmit'] = pd.to_datetime(df1['Resubmit'])\n",
    "df1['Resubmit'] = df1['Resubmit'].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b5a5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = ['rcra_non_haz_exempt','halogens_flag','no_reactivity_flag','layered','viscosity','odor_flag','ph_flag',\n",
    "    'flash_point_flag','boiling_point_flag','btu_per_lbs','pumpable_waste_flag','polymerizable_flag','benzene_waste_flag',\n",
    "    'voc_100_ppm','marine_pollutant_flag','origin_code','sds_attached','specific_gravity','benzene_section_flag',\n",
    "    'max_benzene_flag','benzene_water','prohibited_land_disposal','uts_waste','voc_500_ppm','specialpricing_flag',\n",
    "    'intercompany_flag','mgp_flag','pa_waste_catogory','debris','compressed_gas','analytical_ind',\n",
    "    'generatorknowledge_ind','sds_ind','formulary_attached','analytical_attached','sample_provided','mgplock_flag',\n",
    "    'naics_flag','federal_universal_waste','generator_state_universal_waste']\n",
    "df1[columns_to_fill] = df1[columns_to_fill].fillna(0, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81358cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['water_percentage', 'toc_percentage'] #filling with mean for these 2 columns\n",
    "df1[col] = df1[col].fillna(df1[col].mean(), inplace=False)\n",
    "#df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0bf0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = df1.select_dtypes(include=['object','datetime64']).columns\n",
    "df_dropped_objects = df1.drop(object_columns, axis=1)\n",
    "# df_dropped_objects.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e209b6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RameshMisale\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py:111: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  self.variances_ = np.nanvar(X, axis=0)\n",
      "C:\\Users\\RameshMisale\\anaconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_variance_threshold.py:119: RuntimeWarning: All-NaN slice encountered\n",
      "  self.variances_ = np.nanmin(compare_arr, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VarianceThreshold(threshold=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It will remove the zero variance features\n",
    "\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(df_dropped_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36fc53e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of constant columns: 17\n",
      "Constant column: phenolics_ppm\n",
      "Unique values: [nan  0.]\n",
      "\n",
      "\n",
      "Constant column: cylinder_flag\n",
      "Unique values: [nan  0.]\n",
      "\n",
      "\n",
      "Constant column: minimum_packaging_requirements\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: outbound_profile_taxes\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: inbound_oubound_id_xref\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: ky_report_physical_state_ind\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: ky_report_onsite_ind\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: contract_id\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: sic_code\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: pet_chem_flag\n",
      "Unique values: [nan  0.]\n",
      "\n",
      "\n",
      "Constant column: pet_chem_actual\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: cokeoven_flag\n",
      "Unique values: [ 0. nan]\n",
      "\n",
      "\n",
      "Constant column: container_size_flag\n",
      "Unique values: [ 1. nan]\n",
      "\n",
      "\n",
      "Constant column: waste_type_id\n",
      "Unique values: [nan]\n",
      "\n",
      "\n",
      "Constant column: highly_toxic_flag\n",
      "Unique values: [nan  0.]\n",
      "\n",
      "\n",
      "Constant column: incin_prep_flag\n",
      "Unique values: [nan  1.]\n",
      "\n",
      "\n",
      "Constant column: no_uhcs_flag\n",
      "Unique values: [ 1. nan]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "constant_columns = [column for column in df_dropped_objects.columns\n",
    "                    if column not in df_dropped_objects.columns[var_thres.get_support()]]\n",
    "print(f\"Number of constant columns: {len(constant_columns)}\")\n",
    "for feature in constant_columns:\n",
    "    unique_values = df_dropped_objects[feature].unique()\n",
    "    print(f\"Constant column: {feature}\")\n",
    "    print(f\"Unique values: {unique_values}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e5d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_dropped_objects.drop(constant_columns,axis=1) #dropped the columns here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd3bb04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset,threshold):\n",
    "    col_corr=set()\n",
    "    corr_matrix=dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j]>threshold):\n",
    "                colname=corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167ecb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features=correlation(data,0.8)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3dea019",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.drop(corr_features,axis=1) # dropped the correlated features here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67f2e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_percentage = 90 \n",
    "null_percentage = (data1.isnull().sum() / len(data1)) * 100\n",
    "columns_to_drop = null_percentage[null_percentage > threshold_percentage].index\n",
    "data1_dropped = data1.drop(columns=columns_to_drop)\n",
    "#data1_dropped.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e773400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_dropped = data1_dropped.fillna(0) #filling the null values with 0\n",
    "#data1_dropped.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1838955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59378, 84)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff = data1_dropped.drop(columns=['ReturnCount','DaysAssignReadyForGenSign','profile_id','web_profile_number',\n",
    "                                  'DaysSubmitToAssign','DaysAssignReadyForGenSign','DaysReadyForGenSignSentForGenSign',\n",
    "                                  'DaysDocSignReturnedToApproved','container_type_id','DaysInitiatedToSubmitted',\n",
    "'DaysSentForGenSignToDocSignReturned','vendor_id','ContractID','ldr_class_id','CustomerId','CollectionId',\n",
    "'HCSId','Recert','is_template_profile_flag','AssignUser_id','status_code_id','source_code_id','form_code_id',\n",
    "'management_method_code_id','outbound_profile_id','price_type_code_id','parent_profile_id','health_chemical_identity_id',\n",
    "'flammability_chemical_identity_id','reactivity_chemical_identity_id','process_code_id',\n",
    "'SalesrepID','InternalCoordinatorID','MarketDriverID','InsideSalesRepID','requested_process_code_id'],axis=1)\n",
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c9a3d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            feature        VIF\n",
      "0                             IsHaz  41.992835\n",
      "1                          Resubmit   1.245218\n",
      "2              outbound_profile_ind   1.218593\n",
      "3                     isRecertified   1.227366\n",
      "4                     standard_flag  32.184140\n",
      "..                              ...        ...\n",
      "79               chem_coke_pet_flag   1.282394\n",
      "80                       label_type   2.613335\n",
      "81          federal_universal_waste   1.663563\n",
      "82  generator_state_universal_waste   1.115983\n",
      "83                     revision_num   1.885647\n",
      "\n",
      "[84 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = dff.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(dff.values, i) for i in range(dff.shape[1])]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55917ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IsHaz',\n",
       " 'standard_flag',\n",
       " 'urgent_flag',\n",
       " 'toc_percentage',\n",
       " 'generatorknowledge_ind']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_vif_columns = vif_data[vif_data[\"VIF\"] > 5][\"feature\"].tolist()\n",
    "high_vif_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dc1a5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59378, 79)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final = dff.drop(columns=high_vif_columns)\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c18c5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = df_final.drop('Resubmit', axis='columns')\n",
    "yy= df_final['Resubmit']\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX,yy, test_size=0.2,random_state=42,stratify=yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "285a9bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_0_class,count_1_class = df_final.Resubmit.value_counts()\n",
    "df_class_0 = df_final[df_final[\"Resubmit\"]==0]\n",
    "df_class_1 = df_final[df_final[\"Resubmit\"]==1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX,yy, test_size=0.2,random_state=15,stratify=yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57329f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Under-sampling:\n",
      "0    6757\n",
      "1    6757\n",
      "Name: Resubmit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_class_0_under = df_class_0.sample(count_1_class)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1],axis=0)\n",
    "\n",
    "print('Random Under-sampling:')\n",
    "print(df_test_under.Resubmit.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0da0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = df_test_under.drop('Resubmit', axis='columns')\n",
    "yy= df_test_under['Resubmit']\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX,yy, test_size=0.2,random_state=42,stratify=yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4af186f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training Accuracy: 0.6957728239755804\n",
      "Logistic Regression Testing Accuracy: 0.6888642249352571\n",
      "\n",
      "Precision: 0.6756\n",
      "Recall: 0.7261\n",
      "F1-Score: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RameshMisale\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(XX_train, yy_train)\n",
    "y_pred_lr_train = logistic_regression.predict(XX_train)\n",
    "y_pred_lr_test = logistic_regression.predict(XX_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy_lr_train = accuracy_score(yy_train, y_pred_lr_train)\n",
    "accuracy_lr_test = accuracy_score(yy_test, y_pred_lr_test)\n",
    "print(f'Logistic Regression Training Accuracy: {accuracy_lr_train}')\n",
    "print(f'Logistic Regression Testing Accuracy: {accuracy_lr_test}')\n",
    "\n",
    "# # classification report\n",
    "# print(classification_report(yy_test, y_pred_lr_test))\n",
    "# print(confusion_matrix(yy_test, y_pred_lr_test))\n",
    "\n",
    "precision_lr_test = precision_score(yy_test, y_pred_lr_test)\n",
    "recall_lr_test = recall_score(yy_test, y_pred_lr_test)\n",
    "f1_lr_test = f1_score(yy_test, y_pred_lr_test)\n",
    "\n",
    "# Display precision, recall, and f1-score\n",
    "print(f'\\nPrecision: {precision_lr_test:.4f}')\n",
    "print(f'Recall: {recall_lr_test:.4f}')\n",
    "print(f'F1-Score: {f1_lr_test:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "267edfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to C:\\Users\\RameshMisale\\Downloads\\Harsco_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file_path = (r'C:\\Users\\RameshMisale\\Downloads\\Harsco_model.pkl')\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as file:\n",
    "    # Use pickle.dump() to serialize and save the data to the file\n",
    "    pickle.dump(file_path, file)\n",
    "\n",
    "print(f'Data saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1f84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
